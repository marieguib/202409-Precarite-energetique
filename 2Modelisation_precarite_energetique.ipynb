{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Modélisation statistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: s3fs in c:\\users\\asus\\anaconda3\\lib\\site-packages (2023.4.0)\n",
      "Requirement already satisfied: aiobotocore~=2.5.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from s3fs) (2.5.0)\n",
      "Requirement already satisfied: fsspec==2023.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from s3fs) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from s3fs) (3.8.5)\n",
      "Requirement already satisfied: botocore<1.29.77,>=1.29.76 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiobotocore~=2.5.0->s3fs) (1.29.76)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiobotocore~=2.5.0->s3fs) (1.14.1)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiobotocore~=2.5.0->s3fs) (0.7.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aioitertools>=0.5.1->aiobotocore~=2.5.0->s3fs) (4.7.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from botocore<1.29.77,>=1.29.76->aiobotocore~=2.5.0->s3fs) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from botocore<1.29.77,>=1.29.76->aiobotocore~=2.5.0->s3fs) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from botocore<1.29.77,>=1.29.76->aiobotocore~=2.5.0->s3fs) (1.26.16)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.29.77,>=1.29.76->aiobotocore~=2.5.0->s3fs) (1.16.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (2.2.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install s3fs\n",
    "!pip install pandas\n",
    "!pip install scikit-learn==1.2.2\n",
    "!pip install imbalanced-learn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.1. Chargement et préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importation des données avec code_insee en index\n",
    "donnees = pd.read_csv(\"bdd_finale.csv\", sep=',', encoding='utf-8', index_col=0)\n",
    "donnees.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Formatage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons pouvoir observer le type des données que nous avons. Cela va nous permettre de déterminer si on a besoin de modifier certaines variables pour qu'elles soient bien en variables catégorielles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des variables en variables catégorielles\n",
    "donnees[\"beneficiaire_trans_eco\"] = donnees[\"beneficiaire_trans_eco\"].astype('category')\n",
    "donnees[\"ecoquartiers\"] = donnees[\"ecoquartiers\"].astype('category')\n",
    "donnees[\"beneficiaire_prog\"] = donnees[\"beneficiaire_prog\"].astype('category')\n",
    "donnees[\"gridens7\"] = donnees[\"gridens7\"].astype('category')\n",
    "donnees[\"departement\"] = donnees[\"departement\"].astype('category')\n",
    "donnees[\"gare_tgv\"] = donnees[\"gare_tgv\"].astype('category')\n",
    "donnees[\"CSP_maire\"] = donnees[\"CSP_maire\"].astype('category')\n",
    "\n",
    "\n",
    "# Cas de la variable climat \n",
    "donnees = pd.get_dummies(donnees, columns = [\"climat\"]) # On crée des variables binaires pour la variable climat car on a des chaînes de caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons observer si on a des données manquantes dans notre jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Séparation de la variable à expliquer et des variables explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir X et y pour avoir les variables explicatives et la variable à expliquer beneficiaire_trans_eco\n",
    "X = donnees.drop(columns=['beneficiaire_trans_eco'])\n",
    "\n",
    "# Variable à expliquer : beneficiaire_trans_eco\n",
    "y = donnees[\"beneficiaire_trans_eco\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Convertir les listes en tableaux numpy\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions de X:\", X.shape)\n",
    "print(\"Dimensions de y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.2. Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons d'abord diviser notre jeu de données en jeux d'apprentissage et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.2.1. Régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Construction des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant définir notre modèle de régression logistique, sans pénalité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "\n",
    "etapes_reg_log_oversampler = [('std_scaler', StandardScaler()), # Standardisation des variables\n",
    "        ('oversampler', RandomOverSampler()), # Sur-échantillonnage\n",
    "        ('reg_log', LogisticRegression()), # Régression logistique\n",
    "        ]\n",
    "\n",
    "etapes_reg_log_smote = [('std_scaler', StandardScaler()), # Standardisation des variables pour ne pas donner plus d'importance à une variable qu'à une autre\n",
    "        ('smote', SMOTE()), # Sur-échantillonnage\n",
    "        ('reg_log', LogisticRegression()), # Régression logistique\n",
    "        ]\n",
    "\n",
    "etapes_reg_log_adasyn = [('std_scaler', StandardScaler()), # Standardisation des variables pour ne pas donner plus d'importance à une variable qu'à une autre\n",
    "        ('adasyn', ADASYN()), # Sur-échantillonnage\n",
    "        ('reg_log', LogisticRegression()), # Régression logistique\n",
    "        ]\n",
    "\n",
    "etapes_reg_log_bordeline_smote = [('std_scaler', StandardScaler()), # Standardisation des variables pour ne pas donner plus d'importance à une variable qu'à une autre\n",
    "        ('bordeline_smote', BorderlineSMOTE()), # Sur-échantillonnage\n",
    "        ('reg_log', LogisticRegression()), # Régression logistique\n",
    "        ]\n",
    "\n",
    "# Création des pipelines\n",
    "modele_reg_log_smote  = Pipeline(steps=etapes_reg_log_smote) \n",
    "modele_reg_log_oversampler  = Pipeline(steps=etapes_reg_log_oversampler) \n",
    "modele_reg_log_adasyn  = Pipeline(steps=etapes_reg_log_adasyn)\n",
    "modele_reg_log_bordeline_smote  = Pipeline(steps=etapes_reg_log_bordeline_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraîne le modèle sur les données pour estimer les coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_reg_log_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_reg_log_oversampler.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_reg_log_adasyn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_reg_log_bordeline_smote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche à prédire de nouvelles données grâce aux données test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_reg_log_smote = modele_reg_log_smote.predict_proba(X_test)[:,1]\n",
    "y_pred_reg_log_smote = modele_reg_log_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_reg_log_oversampler = modele_reg_log_oversampler.predict_proba(X_test)[:, 1]\n",
    "y_pred_reg_log_oversampler = modele_reg_log_oversampler.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_reg_log_adasyn = modele_reg_log_adasyn.predict_proba(X_test)[:, 1]\n",
    "y_pred_reg_log_adasyn = modele_reg_log_adasyn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_reg_log_bordeline_smote = modele_reg_log_bordeline_smote.predict_proba(X_test)[:, 1]\n",
    "y_pred_reg_log_bordeline_smote = modele_reg_log_bordeline_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Mesure de la performance des modèles initiaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant évaluer la performance de notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, cohen_kappa_score\n",
    "\n",
    "\n",
    "# Calcul des métriques\n",
    "auc_roc_reg_log_smote = roc_auc_score(y_test, y_proba_reg_log_smote)\n",
    "auc_pr_reg_log_smote  = average_precision_score(y_test, y_proba_reg_log_smote)\n",
    "log_loss_value_reg_log_smote  = log_loss(y_test, y_proba_reg_log_smote)\n",
    "precision_reg_log_smote  = precision_score(y_test, y_pred_reg_log_smote)\n",
    "recall_reg_log_smote  = recall_score(y_test, y_pred_reg_log_smote)\n",
    "f1_reg_log_smote = f1_score(y_test, y_pred_reg_log_smote)\n",
    "mcc_reg_log_smote  = matthews_corrcoef(y_test, y_pred_reg_log_smote)\n",
    "balanced_acc_reg_log_smote  = balanced_accuracy_score(y_test, y_pred_reg_log_smote)\n",
    "specificity_reg_log_smote  = confusion_matrix(y_test, y_pred_reg_log_smote)[0, 0] / (confusion_matrix(y_test, y_pred_reg_log_smote)[0, 0] + confusion_matrix(y_test, y_pred_reg_log_smote)[0, 1])\n",
    "cohen_kappa_reg_log_smote  = cohen_kappa_score(y_test, y_pred_reg_log_smote)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"AUC-ROC: {auc_roc_reg_log_smote }\")\n",
    "print(f\"AUC-PR: {auc_pr_reg_log_smote }\")\n",
    "print(f\"Log Loss: {log_loss_value_reg_log_smote }\")\n",
    "print(f\"Precision: {precision_reg_log_smote }\")\n",
    "print(f\"Recall: {recall_reg_log_smote }\")\n",
    "print(f\"F1 Score: {f1_reg_log_smote }\")\n",
    "print(f\"MCC: {mcc_reg_log_smote }\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc_reg_log_smote }\")\n",
    "print(f\"Specificity: {specificity_reg_log_smote }\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_reg_log_smote }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des métriques\n",
    "\n",
    "# Calcul des métriques\n",
    "auc_roc_reg_log_oversampler = roc_auc_score(y_test, y_proba_reg_log_oversampler)\n",
    "auc_pr_reg_log_oversampler = average_precision_score(y_test, y_proba_reg_log_oversampler)\n",
    "log_loss_value_reg_log_oversampler = log_loss(y_test, y_proba_reg_log_oversampler)\n",
    "precision_reg_log_oversampler = precision_score(y_test, y_pred_reg_log_oversampler)\n",
    "recall_reg_log_oversampler = recall_score(y_test, y_pred_reg_log_oversampler)\n",
    "f1_reg_log_oversampler = f1_score(y_test, y_pred_reg_log_oversampler)\n",
    "mcc_reg_log_oversampler = matthews_corrcoef(y_test, y_pred_reg_log_oversampler)\n",
    "balanced_acc_reg_log_oversampler = balanced_accuracy_score(y_test, y_pred_reg_log_oversampler)\n",
    "specificity_reg_log_oversampler = confusion_matrix(y_test, y_pred_reg_log_oversampler)[0, 0] / (confusion_matrix(y_test, y_pred_reg_log_oversampler)[0, 0] + confusion_matrix(y_test, y_pred_reg_log_oversampler)[0, 1])\n",
    "cohen_kappa_reg_log_oversampler = cohen_kappa_score(y_test, y_pred_reg_log_oversampler)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"AUC-ROC: {auc_roc_reg_log_oversampler}\")\n",
    "print(f\"AUC-PR: {auc_pr_reg_log_oversampler}\")\n",
    "print(f\"Log Loss: {log_loss_value_reg_log_oversampler}\")\n",
    "print(f\"Precision: {precision_reg_log_oversampler}\")\n",
    "print(f\"Recall: {recall_reg_log_oversampler}\")\n",
    "print(f\"F1 Score: {f1_reg_log_oversampler}\")\n",
    "print(f\"MCC: {mcc_reg_log_oversampler}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc_reg_log_oversampler}\")\n",
    "print(f\"Specificity: {specificity_reg_log_oversampler}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_reg_log_oversampler}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des métriques\n",
    "\n",
    "# Calcul des métriques\n",
    "auc_roc_reg_log_adasyn = roc_auc_score(y_test, y_proba_reg_log_adasyn)\n",
    "auc_pr_reg_log_adasyn = average_precision_score(y_test, y_proba_reg_log_adasyn)\n",
    "log_loss_value_reg_log_adasyn = log_loss(y_test, y_proba_reg_log_adasyn)\n",
    "precision_reg_log_adasyn = precision_score(y_test, y_pred_reg_log_adasyn)\n",
    "recall_reg_log_adasyn = recall_score(y_test, y_pred_reg_log_adasyn)\n",
    "f1_reg_log_adasyn = f1_score(y_test, y_pred_reg_log_adasyn)\n",
    "mcc_reg_log_adasyn = matthews_corrcoef(y_test, y_pred_reg_log_adasyn)\n",
    "balanced_acc_reg_log_adasyn = balanced_accuracy_score(y_test, y_pred_reg_log_adasyn)\n",
    "specificity_reg_log_adasyn = confusion_matrix(y_test, y_pred_reg_log_adasyn)[0, 0] / (confusion_matrix(y_test, y_pred_reg_log_adasyn)[0, 0] + confusion_matrix(y_test, y_pred_reg_log_adasyn)[0, 1])\n",
    "cohen_kappa_reg_log_adasyn = cohen_kappa_score(y_test, y_pred_reg_log_adasyn)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"AUC-ROC: {auc_roc_reg_log_adasyn}\")\n",
    "print(f\"AUC-PR: {auc_pr_reg_log_adasyn}\")\n",
    "print(f\"Log Loss: {log_loss_value_reg_log_adasyn}\")\n",
    "print(f\"Precision: {precision_reg_log_adasyn}\")\n",
    "print(f\"Recall: {recall_reg_log_adasyn}\")\n",
    "print(f\"F1 Score: {f1_reg_log_adasyn}\")\n",
    "print(f\"MCC: {mcc_reg_log_adasyn}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc_reg_log_adasyn}\")\n",
    "print(f\"Specificity: {specificity_reg_log_adasyn}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_reg_log_adasyn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des métriques\n",
    "\n",
    "auc_roc_reg_log_borderline_smote = roc_auc_score(y_test, y_proba_reg_log_bordeline_smote)\n",
    "auc_pr_reg_log_borderline_smote = average_precision_score(y_test, y_proba_reg_log_bordeline_smote)\n",
    "log_loss_value_reg_log_borderline_smote = log_loss(y_test, y_proba_reg_log_bordeline_smote)\n",
    "precision_reg_log_borderline_smote = precision_score(y_test, y_pred_reg_log_bordeline_smote)\n",
    "recall_reg_log_borderline_smote = recall_score(y_test, y_pred_reg_log_bordeline_smote)\n",
    "f1_reg_log_borderline_smote = f1_score(y_test, y_pred_reg_log_bordeline_smote)\n",
    "mcc_reg_log_borderline_smote = matthews_corrcoef(y_test, y_pred_reg_log_bordeline_smote)\n",
    "balanced_acc_reg_log_borderline_smote = balanced_accuracy_score(y_test, y_pred_reg_log_bordeline_smote)\n",
    "specificity_reg_log_borderline_smote = confusion_matrix(y_test, y_pred_reg_log_bordeline_smote)[0, 0] / (confusion_matrix(y_test, y_pred_reg_log_bordeline_smote)[0, 0] + confusion_matrix(y_test, y_pred_reg_log_bordeline_smote)[0, 1])\n",
    "cohen_kappa_reg_log_borderline_smote = cohen_kappa_score(y_test, y_pred_reg_log_bordeline_smote)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"AUC-ROC: {auc_roc_reg_log_borderline_smote}\")\n",
    "print(f\"AUC-PR: {auc_pr_reg_log_borderline_smote}\")\n",
    "print(f\"Log Loss: {log_loss_value_reg_log_borderline_smote}\")\n",
    "print(f\"Precision: {precision_reg_log_borderline_smote}\")\n",
    "print(f\"Recall: {recall_reg_log_borderline_smote}\")\n",
    "print(f\"F1 Score: {f1_reg_log_borderline_smote}\")\n",
    "print(f\"MCC: {mcc_reg_log_borderline_smote}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc_reg_log_borderline_smote}\")\n",
    "print(f\"Specificity: {specificity_reg_log_borderline_smote}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_reg_log_borderline_smote}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des courbes ROC\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr_reg_log_smote, tpr_reg_log_smote, _ = roc_curve(y_test, y_proba_reg_log_smote)\n",
    "fpr_reg_log_oversampler, tpr_reg_log_oversampler, _ = roc_curve(y_test, y_proba_reg_log_oversampler)\n",
    "fpr_reg_log_adasyn, tpr_reg_log_adasyn, _ = roc_curve(y_test, y_proba_reg_log_adasyn)\n",
    "fpr_reg_log_bordeline_smote, tpr_reg_log_bordeline_smote, _ = roc_curve(y_test, y_proba_reg_log_bordeline_smote)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_reg_log_smote, tpr_reg_log_smote, label='Régression logistique avec SMOTE')\n",
    "plt.plot(fpr_reg_log_oversampler, tpr_reg_log_oversampler, label='Régression logistique avec RandomOverSampler')\n",
    "plt.plot(fpr_reg_log_adasyn, tpr_reg_log_adasyn, label='Régression logistique avec ADASYN')\n",
    "plt.plot(fpr_reg_log_bordeline_smote, tpr_reg_log_bordeline_smote, label='Régression logistique avec BorderlineSMOTE')\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbes ROC')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des courbes PR\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision_reg_log_smote, recall_reg_log_smote, _ = precision_recall_curve(y_test, y_proba_reg_log_smote)\n",
    "precision_reg_log_oversampler, recall_reg_log_oversampler, _ = precision_recall_curve(y_test, y_proba_reg_log_oversampler)\n",
    "precision_reg_log_adasyn, recall_reg_log_adasyn, _ = precision_recall_curve(y_test, y_proba_reg_log_adasyn)\n",
    "precision_reg_log_bordeline_smote, recall_reg_log_bordeline_smote, _ = precision_recall_curve(y_test, y_proba_reg_log_bordeline_smote)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall_reg_log_smote, precision_reg_log_smote, label='Régression logistique avec SMOTE')\n",
    "plt.plot(recall_reg_log_oversampler, precision_reg_log_oversampler, label='Régression logistique avec RandomOverSampler')\n",
    "plt.plot(recall_reg_log_adasyn, precision_reg_log_adasyn, label='Régression logistique avec ADASYN')\n",
    "plt.plot(recall_reg_log_bordeline_smote, precision_reg_log_bordeline_smote, label='Régression logistique avec BorderlineSMOTE')\n",
    "plt.xlabel('Rappel')\n",
    "plt.ylabel('Précision')\n",
    "plt.title('Courbes PR')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résultats \n",
    "\n",
    "resultats = pd.DataFrame({\n",
    "    \"AUC-ROC\": [auc_roc_reg_log_smote, auc_roc_reg_log_oversampler, auc_roc_reg_log_adasyn, auc_roc_reg_log_borderline_smote],\n",
    "    \"AUC-PR\": [auc_pr_reg_log_smote, auc_pr_reg_log_oversampler, auc_pr_reg_log_adasyn, auc_pr_reg_log_borderline_smote],\n",
    "    \"Log Loss\": [log_loss_value_reg_log_smote, log_loss_value_reg_log_oversampler, log_loss_value_reg_log_adasyn, log_loss_value_reg_log_borderline_smote],\n",
    "   # \"Précision\": [precision_reg_log_smote, precision_reg_log_oversampler, precision_reg_log_adasyn, precision_reg_log_borderline_smote],\n",
    "    #\"Rappel\": [recall_reg_log_smote, recall_reg_log_oversampler, recall_reg_log_adasyn, recall_reg_log_borderline_smote],\n",
    "    \"F1 Score\": [f1_reg_log_smote, f1_reg_log_oversampler, f1_reg_log_adasyn, f1_reg_log_borderline_smote],\n",
    "    \"MCC\": [mcc_reg_log_smote, mcc_reg_log_oversampler, mcc_reg_log_adasyn, mcc_reg_log_borderline_smote],\n",
    "    \"Accuracy\": [balanced_acc_reg_log_smote, balanced_acc_reg_log_oversampler, balanced_acc_reg_log_adasyn, balanced_acc_reg_log_borderline_smote],\n",
    "    \"Spécificité\": [specificity_reg_log_smote, specificity_reg_log_oversampler, specificity_reg_log_adasyn, specificity_reg_log_borderline_smote],\n",
    "    \"Kappa de Cohen\": [cohen_kappa_reg_log_smote, cohen_kappa_reg_log_oversampler, cohen_kappa_reg_log_adasyn, cohen_kappa_reg_log_borderline_smote]\n",
    "}, index=[\"Reg log - SMOTE\", \"Reg log - RandomOverSampler\", \"Reg log - ADASYN\", \"Reg log - BorderlineSMOTE\"])\n",
    "\n",
    "# Arrondir les résultats à 3 chiffres après la virgule\n",
    "resultats = resultats.round(3)\n",
    "\n",
    "resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Ajustement des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la régression logistique, les hyperparamètres les plus courants à optimiser sont :\n",
    "- C : Ce paramètre de régularisation inverse. Une valeur plus petite indique une régularisation plus forte.\n",
    "- solver : L'algorithme utilisé pour l'optimisation. Les choix courants sont 'liblinear', 'lbfgs', 'saga', etc.\n",
    "- penalty : Le type de régularisation à utiliser ('l1', 'l2', 'elasticnet', 'none')\n",
    "- fonction de lien "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustement du modèle\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définir les paramètres de la grille\n",
    "grille_param = {\n",
    "    'reg_log__C': [0.01, 0.1, 1, 10, 100], # Inverse de la force de régularisation : pas d'utilité pour la régression logistique sans régularisation\n",
    "    'reg_log__penalty': ['l1', 'l2', 'elasticnet', 'none'], # Type de régularisation\n",
    "}\n",
    "\n",
    "# Création du GridSearchCV\n",
    "grid_search = GridSearchCV(modele_reg_log_adasyn, grille_param, cv=5)\n",
    "\n",
    "# Entraînement\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meilleurs paramètres\n",
    "print(f\"Meilleurs paramètres : {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meilleur modèle\n",
    "best_model_reg_log = grid_search.best_estimator_\n",
    "best_model_reg_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prévisions\n",
    "y_proba_reg_log_cv = modele_reg_log.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Mesure de la performance des modèles optimisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_roc = roc_auc_score(y_test, y_proba_reg_log_cv)\n",
    "print(f\"AUC-ROC: {auc_roc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des courbes ROC\n",
    "\n",
    "fpr_reg_log_cv, tpr_reg_log_cv, _ = roc_curve(y_test, y_proba_reg_log_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.2.2. Abres de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Construction des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction du modèle d'arbres de décision avec rééquilibrage des classes\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "etapes_arbre_oversampler = [('std_scaler', StandardScaler()), # Standardisation des variables\n",
    "        ('oversampler', RandomOverSampler()), # Sur-échantillonnage\n",
    "        ('arbre', DecisionTreeClassifier()), # Arbre de décision\n",
    "        ]\n",
    "\n",
    "etapes_arbre_smote = [('std_scaler', StandardScaler()), # Standardisation des variables\n",
    "        ('smote', SMOTE()), # Sur-échantillonnage\n",
    "        ('arbre', DecisionTreeClassifier()), # Arbre de décision\n",
    "        ]\n",
    "\n",
    "etapes_arbre_adasyn = [('std_scaler', StandardScaler()), # Standardisation des variables\n",
    "        ('adasyn', ADASYN()), # Sur-échantillonnage\n",
    "        ('arbre', DecisionTreeClassifier()), # Arbre de décision\n",
    "        ]\n",
    "\n",
    "etapes_arbre_bordeline_smote = [('std_scaler', StandardScaler()), # Standardisation des variables\n",
    "        ('bordeline_smote', BorderlineSMOTE()), # Sur-échantillonnage\n",
    "        ('arbre', DecisionTreeClassifier()), # Arbre de décision\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "modele_arbre_oversampler = Pipeline(steps=etapes_arbre_oversampler) # Création du pipeline\n",
    "modele_arbre_smote = Pipeline(steps=etapes_arbre_smote) # Création du pipeline\n",
    "modele_arbre_adasyn = Pipeline(steps=etapes_arbre_adasyn) # Création du pipeline\n",
    "modele_arbre_bordeline_smote = Pipeline(steps=etapes_arbre_bordeline_smote) # Création du pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_arbre_oversampler.fit(X_train, y_train) # Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_arbre_smote.fit(X_train, y_train) # Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_arbre_adasyn.fit(X_train, y_train) # Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_arbre_bordeline_smote.fit(X_train, y_train) # Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions\n",
    "\n",
    "y_proba_arbre_oversampler = modele_arbre_oversampler.predict_proba(X_test)[:, 1]\n",
    "y_pred_arbre_oversampler = modele_arbre_oversampler.predict(X_test)\n",
    "\n",
    "y_proba_arbre_smote = modele_arbre_smote.predict_proba(X_test)[:, 1]\n",
    "y_pred_arbre_smote = modele_arbre_smote.predict(X_test)\n",
    "\n",
    "y_proba_arbre_adasyn = modele_arbre_adasyn.predict_proba(X_test)[:, 1]\n",
    "y_pred_arbre_adasyn = modele_arbre_adasyn.predict(X_test)\n",
    "\n",
    "y_proba_arbre_bordeline_smote = modele_arbre_bordeline_smote.predict_proba(X_test)[:, 1]\n",
    "y_pred_arbre_bordeline_smote = modele_arbre_bordeline_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Mesure de la performance des modèles initiaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des métriques\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, cohen_kappa_score\n",
    "\n",
    "auc_roc_arbre_oversampler = roc_auc_score(y_test, y_proba_arbre_oversampler)\n",
    "auc_pr_arbre_oversampler = average_precision_score(y_test, y_proba_arbre_oversampler)\n",
    "log_loss_value_arbre_oversampler = log_loss(y_test, y_proba_arbre_oversampler)\n",
    "precision_arbre_oversampler = precision_score(y_test, y_pred_arbre_oversampler)\n",
    "recall_arbre_oversampler = recall_score(y_test, y_pred_arbre_oversampler)\n",
    "f1_arbre_oversampler = f1_score(y_test, y_pred_arbre_oversampler)\n",
    "mcc_arbre_oversampler = matthews_corrcoef(y_test, y_pred_arbre_oversampler)\n",
    "balanced_acc_arbre_oversampler = balanced_accuracy_score(y_test, y_pred_arbre_oversampler)\n",
    "specificity_arbre_oversampler = confusion_matrix(y_test, y_pred_arbre_oversampler)[0, 0] / (confusion_matrix(y_test, y_pred_arbre_oversampler)[0, 0] + confusion_matrix(y_test, y_pred_arbre_oversampler)[0, 1])\n",
    "cohen_kappa_arbre_oversampler = cohen_kappa_score(y_test, y_pred_arbre_oversampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_roc_arbre_smote = roc_auc_score(y_test, y_proba_arbre_smote)\n",
    "auc_pr_arbre_smote = average_precision_score(y_test, y_proba_arbre_smote)\n",
    "log_loss_value_arbre_smote = log_loss(y_test, y_proba_arbre_smote)\n",
    "precision_arbre_smote = precision_score(y_test, y_pred_arbre_smote)\n",
    "recall_arbre_smote = recall_score(y_test, y_pred_arbre_smote)\n",
    "f1_arbre_smote = f1_score(y_test, y_pred_arbre_smote)\n",
    "mcc_arbre_smote = matthews_corrcoef(y_test, y_pred_arbre_smote)\n",
    "balanced_acc_arbre_smote = balanced_accuracy_score(y_test, y_pred_arbre_smote)\n",
    "specificity_arbre_smote = confusion_matrix(y_test, y_pred_arbre_smote)[0, 0] / (confusion_matrix(y_test, y_pred_arbre_smote)[0, 0] + confusion_matrix(y_test, y_pred_arbre_smote)[0, 1])\n",
    "cohen_kappa_arbre_smote = cohen_kappa_score(y_test, y_pred_arbre_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_roc_arbre_adasyn = roc_auc_score(y_test, y_proba_arbre_adasyn)\n",
    "auc_pr_arbre_adasyn = average_precision_score(y_test, y_proba_arbre_adasyn)\n",
    "log_loss_value_arbre_adasyn = log_loss(y_test, y_proba_arbre_adasyn)\n",
    "precision_arbre_adasyn = precision_score(y_test, y_pred_arbre_adasyn)\n",
    "recall_arbre_adasyn = recall_score(y_test, y_pred_arbre_adasyn)\n",
    "f1_arbre_adasyn = f1_score(y_test, y_pred_arbre_adasyn)\n",
    "mcc_arbre_adasyn = matthews_corrcoef(y_test, y_pred_arbre_adasyn)\n",
    "balanced_acc_arbre_adasyn = balanced_accuracy_score(y_test, y_pred_arbre_adasyn)\n",
    "specificity_arbre_adasyn = confusion_matrix(y_test, y_pred_arbre_adasyn)[0, 0] / (confusion_matrix(y_test, y_pred_arbre_adasyn)[0, 0] + confusion_matrix(y_test, y_pred_arbre_adasyn)[0, 1])\n",
    "cohen_kappa_arbre_adasyn = cohen_kappa_score(y_test, y_pred_arbre_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_roc_arbre_bordeline_smote = roc_auc_score(y_test, y_proba_arbre_bordeline_smote)\n",
    "auc_pr_arbre_bordeline_smote = average_precision_score(y_test, y_proba_arbre_bordeline_smote)\n",
    "log_loss_value_arbre_bordeline_smote = log_loss(y_test, y_proba_arbre_bordeline_smote)\n",
    "precision_arbre_bordeline_smote = precision_score(y_test, y_pred_arbre_bordeline_smote)\n",
    "recall_arbre_bordeline_smote = recall_score(y_test, y_pred_arbre_bordeline_smote)\n",
    "f1_arbre_bordeline_smote = f1_score(y_test, y_pred_arbre_bordeline_smote)\n",
    "mcc_arbre_bordeline_smote = matthews_corrcoef(y_test, y_pred_arbre_bordeline_smote)\n",
    "balanced_acc_arbre_bordeline_smote = balanced_accuracy_score(y_test, y_pred_arbre_bordeline_smote)\n",
    "specificity_arbre_bordeline_smote = confusion_matrix(y_test, y_pred_arbre_bordeline_smote)[0, 0] / (confusion_matrix(y_test, y_pred_arbre_bordeline_smote)[0, 0] + confusion_matrix(y_test, y_pred_arbre_bordeline_smote)[0, 1])\n",
    "cohen_kappa_arbre_bordeline_smote = cohen_kappa_score(y_test, y_pred_arbre_bordeline_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des résultats\n",
    "resultats = pd.DataFrame({\n",
    "    \"AUC-ROC\": [auc_roc_arbre_oversampler, auc_roc_arbre_smote, auc_roc_arbre_adasyn, auc_roc_arbre_bordeline_smote],\n",
    "    \"AUC-PR\": [auc_pr_arbre_oversampler, auc_pr_arbre_smote, auc_pr_arbre_adasyn, auc_pr_arbre_bordeline_smote],\n",
    "    \"Log Loss\": [log_loss_value_arbre_oversampler, log_loss_value_arbre_smote, log_loss_value_arbre_adasyn, log_loss_value_arbre_bordeline_smote],\n",
    "    #\"Précision\": [precision_arbre_oversampler, precision_arbre_smote, precision_arbre_adasyn, precision_arbre_bordeline_smote],\n",
    "    #\"Rappel\": [recall_arbre_oversampler, recall_arbre_smote, recall_arbre_adasyn, recall_arbre_bordeline_smote],\n",
    "    \"F1 Score\": [f1_arbre_oversampler, f1_arbre_smote, f1_arbre_adasyn, f1_arbre_bordeline_smote],\n",
    "    \"MCC\": [mcc_arbre_oversampler, mcc_arbre_smote, mcc_arbre_adasyn, mcc_arbre_bordeline_smote],\n",
    "    \"Accuracy\": [balanced_acc_arbre_oversampler, balanced_acc_arbre_smote, balanced_acc_arbre_adasyn, balanced_acc_arbre_bordeline_smote],\n",
    "    \"Spécificité\": [specificity_arbre_oversampler, specificity_arbre_smote, specificity_arbre_adasyn, specificity_arbre_bordeline_smote],\n",
    "    \"Kappa de Cohen\": [cohen_kappa_arbre_oversampler, cohen_kappa_arbre_smote, cohen_kappa_arbre_adasyn, cohen_kappa_arbre_bordeline_smote]\n",
    "}, index=[\"Arbre - RandomOverSampler\", \"Arbre - SMOTE\", \"Arbre - ADASYN\", \"Arbre - BorderlineSMOTE\"])\n",
    "\n",
    "# Arrondir les résultats à 3 chiffres après la virgule\n",
    "resultats = resultats.round(3)\n",
    "resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracé des courbes ROC\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr_arbre_oversampler, tpr_arbre_oversampler, _ = roc_curve(y_test, y_proba_arbre_oversampler)\n",
    "fpr_arbre_smote, tpr_arbre_smote, _ = roc_curve(y_test, y_proba_arbre_smote)\n",
    "fpr_arbre_adasyn, tpr_arbre_adasyn, _ = roc_curve(y_test, y_proba_arbre_adasyn)\n",
    "fpr_arbre_bordeline_smote, tpr_arbre_bordeline_smote, _ = roc_curve(y_test, y_proba_arbre_bordeline_smote)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_arbre_oversampler, tpr_arbre_oversampler, label='Arbre avec RandomOverSampler')\n",
    "plt.plot(fpr_arbre_smote, tpr_arbre_smote, label='Arbre avec SMOTE')\n",
    "plt.plot(fpr_arbre_adasyn, tpr_arbre_adasyn, label='Arbre avec ADASYN')\n",
    "plt.plot(fpr_arbre_bordeline_smote, tpr_arbre_bordeline_smote, label='Arbre avec BorderlineSMOTE')\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbes ROC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Ajustement des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score\n",
    "\n",
    "# Définition de la grille des hyperparamètres pour l'arbre de décision\n",
    "param_grid = {\n",
    "    'arbre__criterion': ['gini', 'entropy', 'log_loss'], # Critère d'impureté \n",
    "    'arbre__max_depth': [None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100], # Profondeur maximale de l'arbre\n",
    "    'arbre__min_samples_split': [2, 5, 10, 20,30], # Nombre minimum d'échantillons pour diviser un nœud\n",
    "    'arbre__min_samples_leaf': [1, 2, 4] # Nombre minimum d'échantillons requis à chaque feuille\n",
    "}\n",
    "\n",
    "# Choix des métriques adaptées\n",
    "scoring = {\n",
    "    'F1': make_scorer(f1_score), \n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'AUC': 'roc_auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'oversampler': Pipeline([\n",
    "        ('std_scaler', StandardScaler()), \n",
    "        ('oversampler', RandomOverSampler()), \n",
    "        ('arbre', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    'smote': Pipeline([\n",
    "        ('std_scaler', StandardScaler()), \n",
    "        ('smote', SMOTE()), \n",
    "        ('arbre', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    'adasyn': Pipeline([\n",
    "        ('std_scaler', StandardScaler()), \n",
    "        ('adasyn', ADASYN()), \n",
    "        ('arbre', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    'bordeline_smote': Pipeline([\n",
    "        ('std_scaler', StandardScaler()), \n",
    "        ('bordeline_smote', BorderlineSMOTE()), \n",
    "        ('arbre', DecisionTreeClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# On stocke les meilleurs paramètres pour chaque modèle\n",
    "best_params = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, scoring=scoring, refit='F1', cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params[name] = grid_search.best_params_\n",
    "    print(f\"Meilleurs paramètres pour {name} : {grid_search.best_params_}\")\n",
    "\n",
    "# On stocke les meilleurs modèles\n",
    "best_models = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    best_models[name] = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions\n",
    "y_proba_arbre_oversampler_cv = best_models['oversampler'].predict_proba(X_test)[:, 1]\n",
    "y_proba_arbre_smote_cv = best_models['smote'].predict_proba(X_test)[:, 1]\n",
    "y_proba_arbre_adasyn_cv = best_models['adasyn'].predict_proba(X_test)[:, 1]\n",
    "y_proba_arbre_bordeline_smote_cv = best_models['bordeline_smote'].predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Mesure de la performance des modèles optimisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des métriques\n",
    "\n",
    "auc_roc_arbre_oversampler_cv = roc_auc_score(y_test, y_proba_arbre_oversampler_cv)\n",
    "auc_pr_arbre_oversampler_cv = average_precision_score(y_test, y_proba_arbre_oversampler_cv)\n",
    "log_loss_value_arbre_oversampler_cv = log_loss(y_test, y_proba_arbre_oversampler_cv)\n",
    "precision_arbre_oversampler_cv = precision_score(y_test, y_proba_arbre_oversampler_cv)\n",
    "recall_arbre_oversampler_cv = recall_score(y_test, y_proba_arbre_oversampler_cv)\n",
    "f1_arbre_oversampler_cv = f1_score(y_test, y_proba_arbre_oversampler_cv)\n",
    "mcc_arbre_oversampler_cv = matthews_corrcoef(y_test, y_proba_arbre_oversampler_cv)\n",
    "balanced_acc_arbre_oversampler_cv = balanced_accuracy_score(y_test, y_proba_arbre_oversampler_cv)\n",
    "\n",
    "auc_roc_arbre_smote_cv = roc_auc_score(y_test, y_proba_arbre_smote_cv)\n",
    "auc_pr_arbre_smote_cv = average_precision_score(y_test, y_proba_arbre_smote_cv)\n",
    "log_loss_value_arbre_smote_cv = log_loss(y_test, y_proba_arbre_smote_cv)\n",
    "precision_arbre_smote_cv = precision_score(y_test, y_proba_arbre_smote_cv)\n",
    "recall_arbre_smote_cv = recall_score(y_test, y_proba_arbre_smote_cv)\n",
    "f1_arbre_smote_cv = f1_score(y_test, y_proba_arbre_smote_cv)\n",
    "mcc_arbre_smote_cv = matthews_corrcoef(y_test, y_proba_arbre_smote_cv)\n",
    "balanced_acc_arbre_smote_cv = balanced_accuracy_score(y_test, y_proba_arbre_smote_cv)\n",
    "\n",
    "auc_roc_arbre_adasyn_cv = roc_auc_score(y_test, y_proba_arbre_adasyn_cv)\n",
    "auc_pr_arbre_adasyn_cv = average_precision_score(y_test, y_proba_arbre_adasyn_cv)\n",
    "log_loss_value_arbre_adasyn_cv = log_loss(y_test, y_proba_arbre_adasyn_cv)\n",
    "precision_arbre_adasyn_cv = precision_score(y_test, y_proba_arbre_adasyn_cv)\n",
    "recall_arbre_adasyn_cv = recall_score(y_test, y_proba_arbre_adasyn_cv)\n",
    "f1_arbre_adasyn_cv = f1_score(y_test, y_proba_arbre_adasyn_cv)\n",
    "mcc_arbre_adasyn_cv = matthews_corrcoef(y_test, y_proba_arbre_adasyn_cv)\n",
    "balanced_acc_arbre_adasyn_cv = balanced_accuracy_score(y_test, y_proba_arbre_adasyn_cv)\n",
    "\n",
    "auc_roc_arbre_bordeline_smote_cv = roc_auc_score(y_test, y_proba_arbre_bordeline_smote_cv)\n",
    "auc_pr_arbre_bordeline_smote_cv = average_precision_score(y_test, y_proba_arbre_bordeline_smote_cv)\n",
    "log_loss_value_arbre_bordeline_smote_cv = log_loss(y_test, y_proba_arbre_bordeline_smote_cv)\n",
    "precision_arbre_bordeline_smote_cv = precision_score(y_test, y_proba_arbre_bordeline_smote_cv)\n",
    "recall_arbre_bordeline_smote_cv = recall_score(y_test, y_proba_arbre_bordeline_smote_cv)\n",
    "f1_arbre_bordeline_smote_cv = f1_score(y_test, y_proba_arbre_bordeline_smote_cv)\n",
    "mcc_arbre_bordeline_smote_cv = matthews_corrcoef(y_test, y_proba_arbre_bordeline_smote_cv)\n",
    "balanced_acc_arbre_bordeline_smote_cv = balanced_accuracy_score(y_test, y_proba_arbre_bordeline_smote_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Affichage propre des résultats\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m resultats \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC-ROC\u001b[39m\u001b[38;5;124m\"\u001b[39m: [auc_roc_arbre_oversampler_cv, auc_roc_arbre_smote_cv, auc_roc_arbre_adasyn_cv, auc_roc_arbre_bordeline_smote_cv],\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC-PR\u001b[39m\u001b[38;5;124m\"\u001b[39m: [auc_pr_arbre_oversampler_cv, auc_pr_arbre_smote_cv, auc_pr_arbre_adasyn_cv, auc_pr_arbre_bordeline_smote_cv],\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLog Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [log_loss_value_arbre_oversampler_cv, log_loss_value_arbre_smote_cv, log_loss_value_arbre_adasyn_cv, log_loss_value_arbre_bordeline_smote_cv],\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrécision\u001b[39m\u001b[38;5;124m\"\u001b[39m: [precision_arbre_oversampler_cv, precision_arbre_smote_cv, precision_arbre_adasyn_cv, precision_arbre_bordeline_smote_cv],\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRappel\u001b[39m\u001b[38;5;124m\"\u001b[39m: [recall_arbre_oversampler_cv, recall_arbre_smote_cv, recall_arbre_adasyn_cv, recall_arbre_bordeline_smote_cv],\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score\u001b[39m\u001b[38;5;124m\"\u001b[39m: [f1_arbre_oversampler_cv, f1_arbre_smote_cv, f1_arbre_adasyn_cv, f1_arbre_bordeline_smote_cv],\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMCC\u001b[39m\u001b[38;5;124m\"\u001b[39m: [mcc_arbre_oversampler_cv, mcc_arbre_smote_cv, mcc_arbre_adasyn_cv, mcc_arbre_bordeline_smote_cv],\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: [balanced_acc_arbre_oversampler_cv, balanced_acc_arbre_smote_cv, balanced_acc_arbre_adasyn_cv, balanced_acc_arbre_bordeline_smote_cv]\n\u001b[0;32m     12\u001b[0m }, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArbre - RandomOverSampler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArbre - SMOTE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArbre - ADASYN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArbre - BorderlineSMOTE\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Arrondir les résultats à 3 chiffres après la virgule\u001b[39;00m\n\u001b[0;32m     15\u001b[0m resultats \u001b[38;5;241m=\u001b[39m resultats\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Affichage propre des résultats\n",
    "\n",
    "resultats = pd.DataFrame({\n",
    "    \"AUC-ROC\": [auc_roc_arbre_oversampler_cv, auc_roc_arbre_smote_cv, auc_roc_arbre_adasyn_cv, auc_roc_arbre_bordeline_smote_cv],\n",
    "    \"AUC-PR\": [auc_pr_arbre_oversampler_cv, auc_pr_arbre_smote_cv, auc_pr_arbre_adasyn_cv, auc_pr_arbre_bordeline_smote_cv],\n",
    "    \"Log Loss\": [log_loss_value_arbre_oversampler_cv, log_loss_value_arbre_smote_cv, log_loss_value_arbre_adasyn_cv, log_loss_value_arbre_bordeline_smote_cv],\n",
    "    \"Précision\": [precision_arbre_oversampler_cv, precision_arbre_smote_cv, precision_arbre_adasyn_cv, precision_arbre_bordeline_smote_cv],\n",
    "    \"Rappel\": [recall_arbre_oversampler_cv, recall_arbre_smote_cv, recall_arbre_adasyn_cv, recall_arbre_bordeline_smote_cv],\n",
    "    \"F1 Score\": [f1_arbre_oversampler_cv, f1_arbre_smote_cv, f1_arbre_adasyn_cv, f1_arbre_bordeline_smote_cv],\n",
    "    \"MCC\": [mcc_arbre_oversampler_cv, mcc_arbre_smote_cv, mcc_arbre_adasyn_cv, mcc_arbre_bordeline_smote_cv],\n",
    "    \"Accuracy\": [balanced_acc_arbre_oversampler_cv, balanced_acc_arbre_smote_cv, balanced_acc_arbre_adasyn_cv, balanced_acc_arbre_bordeline_smote_cv]\n",
    "}, index=[\"Arbre - RandomOverSampler\", \"Arbre - SMOTE\", \"Arbre - ADASYN\", \"Arbre - BorderlineSMOTE\"])\n",
    "\n",
    "# Arrondir les résultats à 3 chiffres après la virgule\n",
    "resultats = resultats.round(3)\n",
    "resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2.3. Forêts Aléatoires "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Construction des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction du modèle de forêts aléatoires avec rééquilibrage des classes\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "etapes_rf_oversampler = [('std_scaler', StandardScaler()), # Standardisation des variables\n",
    "        ('oversampler', RandomOverSampler()), # Sur-échantillonnage\n",
    "        ('arbre', RandomForestClassifier()), # Forets aléatoires\n",
    "        ]\n",
    "\n",
    "etapes_rf_smote = [('std_scaler', StandardScaler()), # Standardisation des variables\n",
    "        ('smote', SMOTE()), # Sur-échantillonnage\n",
    "        ('arbre', RandomForestClassifier()), # Forets aléatoires\n",
    "        ]\n",
    "\n",
    "etapes_rf_adasyn = [('std_scaler', StandardScaler()), # Standardisation des variables\n",
    "        ('adasyn', ADASYN()), # Sur-échantillonnage\n",
    "        ('arbre', RandomForestClassifier()), # Forets aléatoires\n",
    "        ]\n",
    "\n",
    "etapes_rf_bordeline_smote = [('std_scaler', StandardScaler()), # Standardisation des variables\n",
    "        ('bordeline_smote', BorderlineSMOTE()), # Sur-échantillonnage\n",
    "        ('rf', RandomForestClassifier()), # Forets aléatoires\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "modele_rf_oversampler = Pipeline(steps=etapes_rf_oversampler) # Création du pipeline\n",
    "modele_rf_smote = Pipeline(steps=etapes_rf_smote) # Création du pipeline\n",
    "modele_rf_adasyn = Pipeline(steps=etapes_rf_adasyn) # Création du pipeline\n",
    "modele_rf_bordeline_smote = Pipeline(steps=etapes_rf_bordeline_smote) # Création du pipeline)\n",
    "\n",
    "modele_rf_oversampler.fit(X_train, y_train) # Entraînement\n",
    "modele_rf_smote.fit(X_train, y_train) # Entraînement\n",
    "modele_rf_adasyn.fit(X_train, y_train) # Entraînement\n",
    "modele_rf_bordeline_smote.fit(X_train, y_train) # Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions\n",
    "\n",
    "y_proba_rf_oversampler = modele_rf_oversampler.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf_oversampler = modele_rf_oversampler.predict(X_test)\n",
    "\n",
    "y_proba_rf_smote = modele_rf_smote.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf_smote = modele_rf_smote.predict(X_test)\n",
    "\n",
    "y_proba_rf_adasyn = modele_rf_adasyn.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf_adasyn = modele_rf_adasyn.predict(X_test)\n",
    "\n",
    "y_proba_rf_bordeline_smote = modele_rf_bordeline_smote.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf_bordeline_smote = modele_rf_bordeline_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Mesure de la performance des modèles initiaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (764029348.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Calcul des métriques\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, cohen_kappa_score\n",
    "\n",
    "auc_roc_rf_oversampler = roc_auc_score(y_test, y_proba_rf_oversampler)\n",
    "auc_pr_rf_oversampler = average_precision_score(y_test, y_proba_rf_oversampler)\n",
    "log_loss_value_rf_oversampler = log_loss(y_test, y_proba_rf_oversampler)\n",
    "precision_rf_oversampler = precision_score(y_test, y_pred_rf_oversampler)\n",
    "recall_rf_oversampler = recall_score(y_test, y_pred_rf_oversampler)\n",
    "f1_rf_oversampler = f1_score(y_test, y_pred_rf_oversampler)\n",
    "mcc_rf_oversampler = matthews_corrcoef(y_test, y_pred_rf_oversampler)\n",
    "balanced_acc_rf_oversampler = balanced_accuracy_score(y_test, y_pred_rf_oversampler)\n",
    "specificity_rf_oversampler = confusion_matrix(y_test, y_pred_rf_oversampler)[0, 0] / (confusion_matrix(y_test, y_pred_rf_oversampler)[0, 0] + confusion_matrix(y_test, y_pred_rf_oversampler)[0, 1])\n",
    "cohen_kappa_rf_oversampler = cohen_kappa_score(y_test, y_pred_rf_oversampler)\n",
    "\n",
    "auc_roc_rf_smote = roc_auc_score(y_test, y_proba_rf_smote)\n",
    "auc_pr_rf_smote = average_precision_score(y_test, y_proba_rf_smote)\n",
    "log_loss_value_rf_smote = log_loss(y_test, y_proba_rf_smote)\n",
    "precision_rf_smote = precision_score(y_test, y_pred_rf_smote)\n",
    "recall_rf_smote = recall_score(y_test, y_pred_rf_smote)\n",
    "f1_rf_smote = f1_score(y_test, y_pred_rf_smote)\n",
    "mcc_rf_smote = matthews_corrcoef(y_test, y_pred_rf_smote)\n",
    "balanced_acc_rf_smote = balanced_accuracy_score(y_test, y_pred_rf_smote)\n",
    "specificity_rf_smote = confusion_matrix(y_test, y_pred_rf_smote)[0, 0] / (confusion_matrix(y_test, y_pred_rf_smote)[0, 0] + confusion_matrix(y_test, y_pred_rf_smote)[0, 1])\n",
    "cohen_kappa_rf_smote = cohen_kappa_score(y_test, y_pred_rf_smote)\n",
    "\n",
    "auc_roc_rf_adasyn = roc_auc_score(y_test, y_proba_rf_adasyn)\n",
    "auc_pr_rf_adasyn = average_precision_score(y_test, y_proba_rf_adasyn)\n",
    "log_loss_value_rf_adasyn = log_loss(y_test, y_proba_rf_adasyn)\n",
    "precision_rf_adasyn = precision_score(y_test, y_pred_rf_adasyn)\n",
    "recall_rf_adasyn = recall_score(y_test, y_pred_rf_adasyn)\n",
    "f1_rf_adasyn = f1_score(y_test, y_pred_rf_adasyn)\n",
    "mcc_rf_adasyn = matthews_corrcoef(y_test, y_pred_rf_adasyn)\n",
    "balanced_acc_rf_adasyn = balanced_accuracy_score(y_test, y_pred_rf_adasyn)\n",
    "specificity_rf_adasyn = confusion_matrix(y_test, y_pred_rf_adasyn)[0, 0] / (confusion_matrix(y_test, y_pred_rf_adasyn)[0, 0] + confusion_matrix(y_test, y_pred_rf_adasyn)[0, 1])\n",
    "cohen_kappa_rf_adasyn = cohen_kappa_score(y_test, y_pred_rf_adasyn)\n",
    "\n",
    "auc_roc_rf_bordeline_smote = roc_auc_score(y_test, y_proba_rf_bordeline_smote)\n",
    "auc_pr_rf_bordeline_smote = average_precision_score(y_test, y_proba_rf_bordeline_smote)\n",
    "log_loss_value_rf_bordeline_smote = log_loss(y_test, y_proba_rf_bordeline_smote)\n",
    "precision_rf_bordeline_smote = precision_score(y_test, y_pred_rf_bordeline_smote)\n",
    "recall_rf_bordeline_smote = recall_score(y_test, y_pred_rf_bordeline_smote)\n",
    "f1_rf_bordeline_smote = f1_score(y_test, y_pred_rf_bordeline_smote)\n",
    "mcc_rf_bordeline_smote = matthews_corrcoef(y_test, y_pred_rf_bordeline_smote)\n",
    "balanced_acc_rf_bordeline_smote = balanced_accuracy_score(y_test, y_pred_rf_bordeline_smote)\n",
    "specificity_rf_bordeline_smote = confusion_matrix(y_test, y_pred_rf_bordeline_smote)[0, 0] / (confusion_matrix(y_test, y_pred_rf_bordeline_smote)[0, 0] + confusion_matrix(y_test, y_pred_rf_bordeline_smote)[0, 1])\n",
    "cohen_kappa_rf_bordeline_smote = cohen_kappa_score(y_test, y_pred_rf_bordeline_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des résultats\n",
    "\n",
    "resultats = pd.DataFrame({\n",
    "    \"AUC-ROC\": [auc_roc_rf_oversampler, auc_roc_rf_smote, auc_roc_rf_adasyn, auc_roc_rf_bordeline_smote],\n",
    "    \"AUC-PR\": [auc_pr_rf_oversampler, auc_pr_rf_smote, auc_pr_rf_adasyn, auc_pr_rf_bordeline_smote],\n",
    "    \"Log Loss\": [log_loss_value_rf_oversampler, log_loss_value_rf_smote, log_loss_value_rf_adasyn, log_loss_value_rf_bordeline_smote],\n",
    "    #\"Précision\": [precision_rf_oversampler, precision_rf_smote, precision_rf_adasyn, precision_rf_bordeline_smote],\n",
    "    #\"Rappel\": [recall_rf_oversampler, recall_rf_smote, recall_rf_adasyn, recall_rf_bordeline_smote],\n",
    "    \"F1 Score\": [f1_rf_oversampler, f1_rf_smote, f1_rf_adasyn, f1_rf_bordeline_smote],\n",
    "    \"MCC\": [mcc_rf_oversampler, mcc_rf_smote, mcc_rf_adasyn, mcc_rf_bordeline_smote],\n",
    "    \"Accuracy\": [balanced_acc_rf_oversampler, balanced_acc_rf_smote, balanced_acc_rf_adasyn, balanced_acc_rf_bordeline_smote],\n",
    "    \"Spécificité\": [specificity_rf_oversampler, specificity_rf_smote, specificity_rf_adasyn, specificity_rf_bordeline_smote],\n",
    "    \"Kappa de Cohen\": [cohen_kappa_rf_oversampler, cohen_kappa_rf_smote, cohen_kappa_rf_adasyn, cohen_kappa_rf_bordeline_smote]\n",
    "}, index=[\"RF - RandomOverSampler\", \"RF - SMOTE\", \"RF - ADASYN\", \"RF - BorderlineSMOTE\"])\n",
    "\n",
    "# Arrondir les résultats à 3 chiffres après la virgule\n",
    "resultats = resultats.round(3)\n",
    "resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Courbes ROC\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_curve\n\u001b[1;32m----> 5\u001b[0m fpr_rf_oversampler, tpr_rf_oversampler, _ \u001b[38;5;241m=\u001b[39m roc_curve(\u001b[43my_test\u001b[49m, y_proba_rf_oversampler)\n\u001b[0;32m      6\u001b[0m fpr_rf_smote, tpr_rf_smote, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_test, y_proba_rf_smote)\n\u001b[0;32m      7\u001b[0m fpr_rf_adasyn, tpr_rf_adasyn, _ \u001b[38;5;241m=\u001b[39m roc_curve(y_test, y_proba_rf_adasyn)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Courbes ROC\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr_rf_oversampler, tpr_rf_oversampler, _ = roc_curve(y_test, y_proba_rf_oversampler)\n",
    "fpr_rf_smote, tpr_rf_smote, _ = roc_curve(y_test, y_proba_rf_smote)\n",
    "fpr_rf_adasyn, tpr_rf_adasyn, _ = roc_curve(y_test, y_proba_rf_adasyn)\n",
    "fpr_rf_bordeline_smote, tpr_rf_bordeline_smote, _ = roc_curve(y_test, y_proba_rf_bordeline_smote)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_rf_oversampler, tpr_rf_oversampler, label='RF avec RandomOverSampler')\n",
    "plt.plot(fpr_rf_smote, tpr_rf_smote, label='RF avec SMOTE')\n",
    "plt.plot(fpr_rf_adasyn, tpr_rf_adasyn, label='RF avec ADASYN')\n",
    "plt.plot(fpr_rf_bordeline_smote, tpr_rf_bordeline_smote, label='RF avec BorderlineSMOTE')\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Courbes ROC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Ajustement des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustement des hyperparamètres par validation croisée\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score\n",
    "\n",
    "# Définition de la grille des hyperparamètres pour les forêts aléatoires\n",
    "\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [100, 200, 300, 400, 500], # Nombre d'arbres\n",
    "    'rf__criterion': ['gini', 'entropy'], # Critère d'impureté\n",
    "    'rf__max_depth': [None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100], # Profondeur maximale de l'arbre\n",
    "    'rf__min_samples_split': [2, 5, 10, 20, 30], # Nombre minimum d'échantillons pour diviser un nœud\n",
    "    'rf__min_samples_leaf': [1, 2, 4] # Nombre minimum d'échantillons requis à chaque feuille\n",
    "}\n",
    "\n",
    "# Choix des métriques adaptées\n",
    "scoring = {\n",
    "    'F1': make_scorer(f1_score), \n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'AUC': 'roc_auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines\n",
    "\n",
    "pipelines = {\n",
    "    'oversampler': Pipeline([\n",
    "        ('std_scaler', StandardScaler()), \n",
    "        ('oversampler', RandomOverSampler()), \n",
    "        ('rf', RandomForestClassifier())\n",
    "    ]),\n",
    "    'smote': Pipeline([\n",
    "        ('std_scaler', StandardScaler()), \n",
    "        ('smote', SMOTE()), \n",
    "        ('rf', RandomForestClassifier())\n",
    "    ]),\n",
    "    'adasyn': Pipeline([\n",
    "        ('std_scaler', StandardScaler()), \n",
    "        ('adasyn', ADASYN()), \n",
    "        ('rf', RandomForestClassifier())\n",
    "    ]),\n",
    "    'bordeline_smote': Pipeline([\n",
    "        ('std_scaler', StandardScaler()), \n",
    "        ('bordeline_smote', BorderlineSMOTE()), \n",
    "        ('rf', RandomForestClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# On stocke les meilleurs paramètres pour chaque modèle\n",
    "best_params = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, scoring=scoring, refit='F1', cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params[name] = grid_search.best_params_\n",
    "    print(f\"Meilleurs paramètres pour {name} : {grid_search.best_params_}\")\n",
    "\n",
    "# On stocke les meilleurs modèles\n",
    "best_models = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    best_models[name] = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions\n",
    "\n",
    "y_proba_rf_oversampler_cv = best_models['oversampler'].predict_proba(X_test)[:, 1]\n",
    "y_proba_rf_smote_cv = best_models['smote'].predict_proba(X_test)[:, 1]\n",
    "y_proba_rf_adasyn_cv = best_models['adasyn'].predict_proba(X_test)[:, 1]\n",
    "y_proba_rf_bordeline_smote_cv = best_models['bordeline_smote'].predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Mesure de la performance des modèles optimisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des métriques\n",
    "\n",
    "auc_roc_rf_oversampler_cv = roc_auc_score(y_test, y_proba_rf_oversampler_cv)\n",
    "auc_pr_rf_oversampler_cv = average_precision_score(y_test, y_proba_rf_oversampler_cv)\n",
    "log_loss_value_rf_oversampler_cv = log_loss(y_test, y_proba_rf_oversampler_cv)\n",
    "precision_rf_oversampler_cv = precision_score(y_test, y_proba_rf_oversampler_cv)\n",
    "recall_rf_oversampler_cv = recall_score(y_test, y_proba_rf_oversampler_cv)\n",
    "f1_rf_oversampler_cv = f1_score(y_test, y_proba_rf_oversampler_cv)\n",
    "mcc_rf_oversampler_cv = matthews_corrcoef(y_test, y_proba_rf_oversampler_cv)\n",
    "balanced_acc_rf_oversampler_cv = balanced_accuracy_score(y_test, y_proba_rf_oversampler_cv)\n",
    "\n",
    "auc_roc_rf_smote_cv = roc_auc_score(y_test, y_proba_rf_smote_cv)\n",
    "auc_pr_rf_smote_cv = average_precision_score(y_test, y_proba_rf_smote_cv)\n",
    "log_loss_value_rf_smote_cv = log_loss(y_test, y_proba_rf_smote_cv)\n",
    "precision_rf_smote_cv = precision_score(y_test, y_proba_rf_smote_cv)\n",
    "recall_rf_smote_cv = recall_score(y_test, y_proba_rf_smote_cv)\n",
    "f1_rf_smote_cv = f1_score(y_test, y_proba_rf_smote_cv)\n",
    "mcc_rf_smote_cv = matthews_corrcoef(y_test, y_proba_rf_smote_cv)\n",
    "balanced_acc_rf_smote_cv = balanced_accuracy_score(y_test, y_proba_rf_smote_cv)\n",
    "\n",
    "auc_roc_rf_adasyn_cv = roc_auc_score(y_test, y_proba_rf_adasyn_cv)\n",
    "auc_pr_rf_adasyn_cv = average_precision_score(y_test, y_proba_rf_adasyn_cv)\n",
    "log_loss_value_rf_adasyn_cv = log_loss(y_test, y_proba_rf_adasyn_cv)\n",
    "precision_rf_adasyn_cv = precision_score(y_test, y_proba_rf_adasyn_cv)\n",
    "recall_rf_adasyn_cv = recall_score(y_test, y_proba_rf_adasyn_cv)\n",
    "f1_rf_adasyn_cv = f1_score(y_test, y_proba_rf_adasyn_cv)\n",
    "mcc_rf_adasyn_cv = matthews_corrcoef(y_test, y_proba_rf_adasyn_cv)\n",
    "balanced_acc_rf_adasyn_cv = balanced_accuracy_score(y_test, y_proba_rf_adasyn_cv)\n",
    "\n",
    "auc_roc_rf_bordeline_smote_cv = roc_auc_score(y_test, y_proba_rf_bordeline_smote_cv)\n",
    "auc_pr_rf_bordeline_smote_cv = average_precision_score(y_test, y_proba_rf_bordeline_smote_cv)\n",
    "log_loss_value_rf_bordeline_smote_cv = log_loss(y_test, y_proba_rf_bordeline_smote_cv)\n",
    "precision_rf_bordeline_smote_cv = precision_score(y_test, y_proba_rf_bordeline_smote_cv)\n",
    "recall_rf_bordeline_smote_cv = recall_score(y_test, y_proba_rf_bordeline_smote_cv)\n",
    "f1_rf_bordeline_smote_cv = f1_score(y_test, y_proba_rf_bordeline_smote_cv)\n",
    "mcc_rf_bordeline_smote_cv = matthews_corrcoef(y_test, y_proba_rf_bordeline_smote_cv)\n",
    "balanced_acc_rf_bordeline_smote_cv = balanced_accuracy_score(y_test, y_proba_rf_bordeline_smote_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des résultats\n",
    "\n",
    "resultats = pd.DataFrame({\n",
    "    \"AUC-ROC\": [auc_roc_rf_oversampler_cv, auc_roc_rf_smote_cv, auc_roc_rf_adasyn_cv, auc_roc_rf_bordeline_smote_cv],\n",
    "    \"AUC-PR\": [auc_pr_rf_oversampler_cv, auc_pr_rf_smote_cv, auc_pr_rf_adasyn_cv, auc_pr_rf_bordeline_smote_cv],\n",
    "    \"Log Loss\": [log_loss_value_rf_oversampler_cv, log_loss_value_rf_smote_cv, log_loss_value_rf_adasyn_cv, log_loss_value_rf_bordeline_smote_cv],\n",
    "    \"Précision\": [precision_rf_oversampler_cv, precision_rf_smote_cv, precision_rf_adasyn_cv, precision_rf_bordeline_smote_cv],\n",
    "    \"Rappel\": [recall_rf_oversampler_cv, recall_rf_smote_cv, recall_rf_adasyn_cv, recall_rf_bordeline_smote_cv],\n",
    "    \"F1 Score\": [f1_rf_oversampler_cv, f1_rf_smote_cv, f1_rf_adasyn_cv, f1_rf_bordeline_smote_cv],\n",
    "    \"MCC\": [mcc_rf_oversampler_cv, mcc_rf_smote_cv, mcc_rf_adasyn_cv, mcc_rf_bordeline_smote_cv],\n",
    "    \"Accuracy\": [balanced_acc_rf_oversampler_cv, balanced_acc_rf_smote_cv, balanced_acc_rf_adasyn_cv, balanced_acc_rf_bordeline_smote_cv]\n",
    "}, index=[\"RF - RandomOverSampler\", \"RF - SMOTE\", \"RF - ADASYN\", \"RF - BorderlineSMOTE\"])\n",
    "\n",
    "# Arrondir les résultats à 3 chiffres après la virgule\n",
    "resultats = resultats.round(3)\n",
    "resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2.4. Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Modèle de gradient boosting\n",
    "etapes = ([(\"std_scaler\", StandardScaler()),\n",
    "              (\"smote\", SMOTE()),\n",
    "              (\"clf_boosting\", GradientBoostingClassifier())\n",
    "    ])\n",
    "\n",
    "model_gradient_boosting = Pipeline(steps=etapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gradient_boosting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gradient_boosting = model_gradient_boosting.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Mesure de la performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_gradient_boosting = modele_reg_log.score(X_test, y_test)\n",
    "print(\"Le score du modèle est : \", score_gradient_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat_conf_gradient_boosting = confusion_matrix(y_test, y_pred_gradient_boosting)\n",
    "print(\"La matrice de confusion est : \\n\", mat_conf_gradient_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "modalites =[0,1] \n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(modalites))\n",
    "plt.xticks(tick_marks, modalites)\n",
    "plt.yticks(tick_marks, modalites)\n",
    "\n",
    "sns.heatmap(pd.DataFrame(mat_conf_gradient_boosting), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Matrice de confusion', y=1.1)\n",
    "plt.ylabel('Valeur observée')\n",
    "plt.xlabel('valeur prédite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred_prob_gradient_boosting = model_gradient_boosting.predict_proba(X_test)[:, 1] # probabilité que la classe soit 1\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_gradient_boosting) # calcul des taux de faux positifs et vrais positifs\n",
    "roc_auc = auc(fpr, tpr) # calcul de l'aire sous la courbe ROC\n",
    "\n",
    "# Tracé de la courbe ROC\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, label='Courbe ROC (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--') # ligne en pointillés représentant la performance d'un classificateur aléatoire\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"Taux de faux positif (1 - spécificité)\")\n",
    "plt.ylabel('Taux de vrai positif (sensibilité)')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du score AUC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score_auc_gradient_boosting = roc_auc_score(y_test, y_pred_prob_gradient_boosting)\n",
    "score_auc_gradient_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la précision\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_gradient_boosting = precision_score(y_test, y_pred_gradient_boosting)\n",
    "print(\"Precision:\", precision_gradient_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_gradient_boosting = recall_score(y_test, y_pred_gradient_boosting)\n",
    "print(\"Recall:\", recall_gradient_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate and print F1-score\n",
    "f1_gradient_boosting = f1_score(y_test, y_pred_gradient_boosting)\n",
    "print(\"F1-Score:\", f1_gradient_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résumé du modèle de gradient boosting\n",
    "\n",
    "print(\"Modèle de gradient boosting \\n\")\n",
    "print(\"Score AUC:\", score_auc_gradient_boosting) \n",
    "print(\"F1-Score:\", f1_gradient_boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2.5. Régression ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Régression ridge\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "etapes = ([\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "    (\"smote\", SMOTE()),\n",
    "    (\"clf_ridge\", RidgeClassifier())\n",
    "])\n",
    "\n",
    "model_reg_ridge = Pipeline(steps=etapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_ridge = model_reg_ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Mesure de la performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_reg_ridge = modele_reg_log.score(X_test, y_test)\n",
    "print(\"Le score du modèle est : \", score_reg_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de confusion\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat_conf_reg_ridge = confusion_matrix(y_test, y_pred_reg_ridge)\n",
    "print(\"La matrice de confusion est : \\n\", mat_conf_reg_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "modalites =[0,1] \n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(modalites))\n",
    "plt.xticks(tick_marks, modalites)\n",
    "plt.yticks(tick_marks, modalites)\n",
    "\n",
    "sns.heatmap(pd.DataFrame(mat_conf_reg_ridge), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Matrice de confusion', y=1.1)\n",
    "plt.ylabel('Valeur observée')\n",
    "plt.xlabel('valeur prédite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred_prob_reg_ridge = model_gradient_boosting.predict_proba(X_test)[:, 1] # probabilité que la classe soit 1\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_reg_ridge) # calcul des taux de faux positifs et vrais positifs\n",
    "roc_auc = auc(fpr, tpr) # calcul de l'aire sous la courbe ROC\n",
    "\n",
    "# Tracé de la courbe ROC\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, label='Courbe ROC (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--') # ligne en pointillés représentant la performance d'un classificateur aléatoire\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"Taux de faux positif (1 - spécificité)\")\n",
    "plt.ylabel('Taux de vrai positif (sensibilité)')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du score AUC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score_auc_reg_ridge = roc_auc_score(y_test, y_pred_prob_reg_ridge)\n",
    "score_auc_reg_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la précision\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_reg_ridge = precision_score(y_test, y_pred_reg_ridge)\n",
    "print(\"Precision:\", precision_reg_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_reg_ridge = recall_score(y_test, y_pred_reg_ridge)\n",
    "print(\"Recall:\", recall_reg_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Calculate and print F1-score\n",
    "f1_reg_ridge = f1_score(y_test, y_pred_reg_ridge)\n",
    "print(\"F1-Score:\", f1_reg_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résumé du modèle de gradient boosting\n",
    "\n",
    "print(\"Modèle de gradient boosting \\n\")\n",
    "print(\"Score AUC:\", score_auc_reg_ridge) \n",
    "print(\"F1-Score:\", f1_reg_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.3. Comparaison des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des modèles\n",
    "\n",
    "print(\"Régression logistique \\n\")\n",
    "print(\"Score AUC:\", score_auc_reg_log)\n",
    "print(\"F1-Score:\", f1_reg_log)\n",
    "\n",
    "print(\"Forêts aléatoires \\n\")\n",
    "print(\"Score AUC:\", score_auc_random_forest)\n",
    "print(\"F1-Score:\", f1_random_forest)\n",
    "\n",
    "print(\"Gradient boosting \\n\")\n",
    "print(\"Score AUC:\", score_auc_gradient_boosting)\n",
    "print(\"F1-Score:\", f1_gradient_boosting)\n",
    "\n",
    "print(\"Régression ridge \\n\")\n",
    "print(\"Score AUC:\", score_auc_reg_ridge)\n",
    "print(\"F1-Score:\", f1_reg_ridge)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
